{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('SMSSpamCollection.txt', sep = '\\t', header = None)\n",
    "dataset.columns = ['label', 'body_text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "ps = nltk.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['body_len'] = dataset['body_text'].apply(lambda x : len(x) - x.count(' '))\n",
    "def count_punct(text):\n",
    "    count = sum([1 for char in text if char in string.punctuation])\n",
    "    return round(count/(len(text) - text.count(\" \")), 3)* 100\n",
    "dataset['punct%'] = dataset['body_text'].apply(lambda x:count_punct(x))\n",
    "\n",
    "def count_capital(text):\n",
    "    text_no_punct = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    count = sum([1 for char in text_no_punct if (char == char.upper() and char != \" \")])\n",
    "    return count\n",
    "dataset['cap_count'] = dataset['body_text'].apply(lambda x: count_capital(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = \" \".join([char for char in text if char not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    text = [ps.stem(word) for word in tokens if word not in stopwords]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tv = TfidfVectorizer(analyzer = clean_text)\n",
    "tm_tv = tv.fit_transform(dataset['body_text'])\n",
    "X_features_tv = pd.concat([dataset['body_len'], dataset['punct%'], dataset['cap_count'], pd.DataFrame(tm_tv.toarray())], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(analyzer = clean_text)\n",
    "tm_cv = tv.fit_transform(dataset['body_text'])\n",
    "X_features_cv = pd.concat([dataset['body_len'], dataset['punct%'], dataset['cap_count'], pd.DataFrame(tm_tv.toarray())], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features_tv, dataset['label'], test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainGB(n_est, depth, lr):\n",
    "    gb = GradientBoostingClassifier(n_estimators = n_est, max_depth = depth, learning_rate = lr)\n",
    "    gb_model = gb.fit(X_train, y_train)\n",
    "    y_pred = gb_model.predict(X_test)\n",
    "    precision, recall, fscore, support = score(y_test, y_pred, pos_label = 'spam', average = 'binary')\n",
    "    print('Est: {}, depth: {}, learning_rate: {}----->Precision: {}, Recall: {}, Accuracy: {}'.format(n_est, depth, lr,\n",
    "                                                                                                      round(precision, 3),\n",
    "                                                                                                      round(recall, 3),\n",
    "                                                                                                      round((y_pred == y_test).sum() / len(y_pred), 3)\n",
    "                                                                                                     ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Est: 100, depth: 3, learning_rate: 0.01----->Precision: 0.958, Recall: 0.838, Accuracy: 0.976\n",
      "Est: 100, depth: 3, learning_rate: 0.1----->Precision: 0.937, Recall: 0.875, Accuracy: 0.978\n",
      "Est: 100, depth: 3, learning_rate: 1----->Precision: 0.922, Recall: 0.868, Accuracy: 0.975\n",
      "Est: 100, depth: 7, learning_rate: 0.01----->Precision: 0.945, Recall: 0.882, Accuracy: 0.979\n",
      "Est: 100, depth: 7, learning_rate: 0.1----->Precision: 0.937, Recall: 0.875, Accuracy: 0.978\n",
      "Est: 100, depth: 7, learning_rate: 1----->Precision: 0.923, Recall: 0.882, Accuracy: 0.977\n",
      "Est: 100, depth: 13, learning_rate: 0.01----->Precision: 0.917, Recall: 0.897, Accuracy: 0.978\n",
      "Est: 100, depth: 13, learning_rate: 0.1----->Precision: 0.898, Recall: 0.904, Accuracy: 0.976\n",
      "Est: 100, depth: 13, learning_rate: 1----->Precision: 0.879, Recall: 0.904, Accuracy: 0.973\n",
      "Est: 100, depth: 19, learning_rate: 0.01----->Precision: 0.917, Recall: 0.897, Accuracy: 0.978\n",
      "Est: 100, depth: 19, learning_rate: 0.1----->Precision: 0.904, Recall: 0.904, Accuracy: 0.977\n",
      "Est: 100, depth: 19, learning_rate: 1----->Precision: 0.885, Recall: 0.904, Accuracy: 0.974\n",
      "Est: 200, depth: 3, learning_rate: 0.01----->Precision: 0.959, Recall: 0.853, Accuracy: 0.978\n",
      "Est: 200, depth: 3, learning_rate: 0.1----->Precision: 0.937, Recall: 0.868, Accuracy: 0.977\n",
      "Est: 200, depth: 3, learning_rate: 1----->Precision: 0.896, Recall: 0.882, Accuracy: 0.973\n",
      "Est: 200, depth: 7, learning_rate: 0.01----->Precision: 0.938, Recall: 0.89, Accuracy: 0.979\n",
      "Est: 200, depth: 7, learning_rate: 0.1----->Precision: 0.945, Recall: 0.882, Accuracy: 0.979\n",
      "Est: 200, depth: 7, learning_rate: 1----->Precision: 0.916, Recall: 0.882, Accuracy: 0.976\n",
      "Est: 200, depth: 13, learning_rate: 0.01----->Precision: 0.904, Recall: 0.904, Accuracy: 0.977\n",
      "Est: 200, depth: 13, learning_rate: 0.1----->Precision: 0.911, Recall: 0.904, Accuracy: 0.978\n",
      "Est: 200, depth: 13, learning_rate: 1----->Precision: 0.866, Recall: 0.904, Accuracy: 0.971\n",
      "Est: 200, depth: 19, learning_rate: 0.01----->Precision: 0.891, Recall: 0.897, Accuracy: 0.974\n",
      "Est: 200, depth: 19, learning_rate: 0.1----->Precision: 0.885, Recall: 0.904, Accuracy: 0.974\n",
      "Est: 200, depth: 19, learning_rate: 1----->Precision: 0.885, Recall: 0.904, Accuracy: 0.974\n",
      "Est: 400, depth: 3, learning_rate: 0.01----->Precision: 0.937, Recall: 0.875, Accuracy: 0.978\n",
      "Est: 400, depth: 3, learning_rate: 0.1----->Precision: 0.96, Recall: 0.875, Accuracy: 0.98\n",
      "Est: 400, depth: 3, learning_rate: 1----->Precision: 0.896, Recall: 0.882, Accuracy: 0.973\n",
      "Est: 400, depth: 7, learning_rate: 0.01----->Precision: 0.93, Recall: 0.875, Accuracy: 0.977\n",
      "Est: 400, depth: 7, learning_rate: 0.1----->Precision: 0.938, Recall: 0.89, Accuracy: 0.979\n",
      "Est: 400, depth: 7, learning_rate: 1----->Precision: 0.902, Recall: 0.882, Accuracy: 0.974\n",
      "Est: 400, depth: 13, learning_rate: 0.01----->Precision: 0.898, Recall: 0.904, Accuracy: 0.976\n",
      "Est: 400, depth: 13, learning_rate: 0.1----->Precision: 0.925, Recall: 0.912, Accuracy: 0.98\n",
      "Est: 400, depth: 13, learning_rate: 1----->Precision: 0.891, Recall: 0.904, Accuracy: 0.975\n",
      "Est: 400, depth: 19, learning_rate: 0.01----->Precision: 0.879, Recall: 0.904, Accuracy: 0.973\n",
      "Est: 400, depth: 19, learning_rate: 0.1----->Precision: 0.891, Recall: 0.904, Accuracy: 0.975\n",
      "Est: 400, depth: 19, learning_rate: 1----->Precision: 0.872, Recall: 0.904, Accuracy: 0.972\n",
      "Est: 500, depth: 3, learning_rate: 0.01----->Precision: 0.937, Recall: 0.875, Accuracy: 0.978\n",
      "Est: 500, depth: 3, learning_rate: 0.1----->Precision: 0.952, Recall: 0.875, Accuracy: 0.979\n",
      "Est: 500, depth: 3, learning_rate: 1----->Precision: 0.896, Recall: 0.882, Accuracy: 0.973\n",
      "Est: 500, depth: 7, learning_rate: 0.01----->Precision: 0.93, Recall: 0.882, Accuracy: 0.978\n",
      "Est: 500, depth: 7, learning_rate: 0.1----->Precision: 0.945, Recall: 0.882, Accuracy: 0.979\n",
      "Est: 500, depth: 7, learning_rate: 1----->Precision: 0.896, Recall: 0.89, Accuracy: 0.974\n",
      "Est: 500, depth: 13, learning_rate: 0.01----->Precision: 0.898, Recall: 0.904, Accuracy: 0.976\n",
      "Est: 500, depth: 13, learning_rate: 0.1----->Precision: 0.918, Recall: 0.904, Accuracy: 0.978\n",
      "Est: 500, depth: 13, learning_rate: 1----->Precision: 0.899, Recall: 0.912, Accuracy: 0.977\n",
      "Est: 500, depth: 19, learning_rate: 0.01----->Precision: 0.879, Recall: 0.904, Accuracy: 0.973\n",
      "Est: 500, depth: 19, learning_rate: 0.1----->Precision: 0.904, Recall: 0.904, Accuracy: 0.977\n",
      "Est: 500, depth: 19, learning_rate: 1----->Precision: 0.891, Recall: 0.904, Accuracy: 0.975\n"
     ]
    }
   ],
   "source": [
    "for n_est in [100, 200, 400, 500]:\n",
    "    for depth in [3, 7, 13, 19]:\n",
    "        for lr in [0.01, 0.1, 1]:\n",
    "            trainGB(n_est, depth, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>11.659200</td>\n",
       "      <td>0.157523</td>\n",
       "      <td>0.013564</td>\n",
       "      <td>0.003253</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>150</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 7, 'n_esti...</td>\n",
       "      <td>0.982960</td>\n",
       "      <td>0.987444</td>\n",
       "      <td>0.980251</td>\n",
       "      <td>0.978456</td>\n",
       "      <td>0.982944</td>\n",
       "      <td>0.982411</td>\n",
       "      <td>0.003040</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7.586119</td>\n",
       "      <td>0.156151</td>\n",
       "      <td>0.009575</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 7, 'n_esti...</td>\n",
       "      <td>0.980269</td>\n",
       "      <td>0.986547</td>\n",
       "      <td>0.978456</td>\n",
       "      <td>0.976661</td>\n",
       "      <td>0.982944</td>\n",
       "      <td>0.980975</td>\n",
       "      <td>0.003475</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9.184656</td>\n",
       "      <td>0.482383</td>\n",
       "      <td>0.011369</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>0.1</td>\n",
       "      <td>11</td>\n",
       "      <td>150</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 11, 'n_est...</td>\n",
       "      <td>0.979372</td>\n",
       "      <td>0.983857</td>\n",
       "      <td>0.979354</td>\n",
       "      <td>0.975763</td>\n",
       "      <td>0.979354</td>\n",
       "      <td>0.979540</td>\n",
       "      <td>0.002569</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8.907515</td>\n",
       "      <td>0.724837</td>\n",
       "      <td>0.011370</td>\n",
       "      <td>0.002239</td>\n",
       "      <td>0.1</td>\n",
       "      <td>11</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 11, 'n_est...</td>\n",
       "      <td>0.979372</td>\n",
       "      <td>0.984753</td>\n",
       "      <td>0.980251</td>\n",
       "      <td>0.975763</td>\n",
       "      <td>0.977558</td>\n",
       "      <td>0.979540</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>8.874552</td>\n",
       "      <td>0.768765</td>\n",
       "      <td>0.015558</td>\n",
       "      <td>0.006663</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 15, 'n_est...</td>\n",
       "      <td>0.972197</td>\n",
       "      <td>0.983857</td>\n",
       "      <td>0.979354</td>\n",
       "      <td>0.972172</td>\n",
       "      <td>0.970377</td>\n",
       "      <td>0.975591</td>\n",
       "      <td>0.005155</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "1      11.659200      0.157523         0.013564        0.003253   \n",
       "0       7.586119      0.156151         0.009575        0.000798   \n",
       "3       9.184656      0.482383         0.011369        0.001018   \n",
       "2       8.907515      0.724837         0.011370        0.002239   \n",
       "4       8.874552      0.768765         0.015558        0.006663   \n",
       "\n",
       "  param_learning_rate param_max_depth param_n_estimators  \\\n",
       "1                 0.1               7                150   \n",
       "0                 0.1               7                100   \n",
       "3                 0.1              11                150   \n",
       "2                 0.1              11                100   \n",
       "4                 0.1              15                100   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "1  {'learning_rate': 0.1, 'max_depth': 7, 'n_esti...           0.982960   \n",
       "0  {'learning_rate': 0.1, 'max_depth': 7, 'n_esti...           0.980269   \n",
       "3  {'learning_rate': 0.1, 'max_depth': 11, 'n_est...           0.979372   \n",
       "2  {'learning_rate': 0.1, 'max_depth': 11, 'n_est...           0.979372   \n",
       "4  {'learning_rate': 0.1, 'max_depth': 15, 'n_est...           0.972197   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "1           0.987444           0.980251           0.978456           0.982944   \n",
       "0           0.986547           0.978456           0.976661           0.982944   \n",
       "3           0.983857           0.979354           0.975763           0.979354   \n",
       "2           0.984753           0.980251           0.975763           0.977558   \n",
       "4           0.983857           0.979354           0.972172           0.970377   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "1         0.982411        0.003040                1  \n",
       "0         0.980975        0.003475                2  \n",
       "3         0.979540        0.002569                3  \n",
       "2         0.979540        0.003030                4  \n",
       "4         0.975591        0.005155                5  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier()\n",
    "param = {'n_estimators':[100, 150], 'max_depth':[7,11,15,19], 'learning_rate':[0.1]}\n",
    "gs = GridSearchCV(gb, param, cv = 5, n_jobs = -1)\n",
    "gs_model = gs.fit(X_features_tv, dataset['label'])\n",
    "pd.DataFrame(gs_model.cv_results_).sort_values('mean_test_score', ascending = False)[0:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8.804869</td>\n",
       "      <td>0.111613</td>\n",
       "      <td>0.011401</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 7, 'n_esti...</td>\n",
       "      <td>0.981166</td>\n",
       "      <td>0.987444</td>\n",
       "      <td>0.980251</td>\n",
       "      <td>0.978456</td>\n",
       "      <td>0.981149</td>\n",
       "      <td>0.981693</td>\n",
       "      <td>0.003040</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>13.590291</td>\n",
       "      <td>0.167053</td>\n",
       "      <td>0.015503</td>\n",
       "      <td>0.001549</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>150</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 7, 'n_esti...</td>\n",
       "      <td>0.981166</td>\n",
       "      <td>0.986547</td>\n",
       "      <td>0.980251</td>\n",
       "      <td>0.977558</td>\n",
       "      <td>0.982047</td>\n",
       "      <td>0.981514</td>\n",
       "      <td>0.002932</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>10.457935</td>\n",
       "      <td>1.043579</td>\n",
       "      <td>0.012205</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>0.1</td>\n",
       "      <td>11</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 11, 'n_est...</td>\n",
       "      <td>0.979372</td>\n",
       "      <td>0.984753</td>\n",
       "      <td>0.979354</td>\n",
       "      <td>0.975763</td>\n",
       "      <td>0.978456</td>\n",
       "      <td>0.979540</td>\n",
       "      <td>0.002922</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11.201084</td>\n",
       "      <td>0.740664</td>\n",
       "      <td>0.013963</td>\n",
       "      <td>0.000880</td>\n",
       "      <td>0.1</td>\n",
       "      <td>11</td>\n",
       "      <td>150</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 11, 'n_est...</td>\n",
       "      <td>0.979372</td>\n",
       "      <td>0.984753</td>\n",
       "      <td>0.980251</td>\n",
       "      <td>0.975763</td>\n",
       "      <td>0.976661</td>\n",
       "      <td>0.979360</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>10.706933</td>\n",
       "      <td>0.837969</td>\n",
       "      <td>0.012800</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 15, 'n_est...</td>\n",
       "      <td>0.972197</td>\n",
       "      <td>0.983857</td>\n",
       "      <td>0.979354</td>\n",
       "      <td>0.972172</td>\n",
       "      <td>0.971275</td>\n",
       "      <td>0.975771</td>\n",
       "      <td>0.004983</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       8.804869      0.111613         0.011401        0.000800   \n",
       "1      13.590291      0.167053         0.015503        0.001549   \n",
       "2      10.457935      1.043579         0.012205        0.000749   \n",
       "3      11.201084      0.740664         0.013963        0.000880   \n",
       "4      10.706933      0.837969         0.012800        0.000977   \n",
       "\n",
       "  param_learning_rate param_max_depth param_n_estimators  \\\n",
       "0                 0.1               7                100   \n",
       "1                 0.1               7                150   \n",
       "2                 0.1              11                100   \n",
       "3                 0.1              11                150   \n",
       "4                 0.1              15                100   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'learning_rate': 0.1, 'max_depth': 7, 'n_esti...           0.981166   \n",
       "1  {'learning_rate': 0.1, 'max_depth': 7, 'n_esti...           0.981166   \n",
       "2  {'learning_rate': 0.1, 'max_depth': 11, 'n_est...           0.979372   \n",
       "3  {'learning_rate': 0.1, 'max_depth': 11, 'n_est...           0.979372   \n",
       "4  {'learning_rate': 0.1, 'max_depth': 15, 'n_est...           0.972197   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.987444           0.980251           0.978456           0.981149   \n",
       "1           0.986547           0.980251           0.977558           0.982047   \n",
       "2           0.984753           0.979354           0.975763           0.978456   \n",
       "3           0.984753           0.980251           0.975763           0.976661   \n",
       "4           0.983857           0.979354           0.972172           0.971275   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.981693        0.003040                1  \n",
       "1         0.981514        0.002932                2  \n",
       "2         0.979540        0.002922                3  \n",
       "3         0.979360        0.003166                4  \n",
       "4         0.975771        0.004983                5  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier()\n",
    "param = {'n_estimators':[100, 150], 'max_depth':[7,11,15,19], 'learning_rate':[0.1]}\n",
    "gs_cv = GridSearchCV(gb, param, cv = 5, n_jobs = -1)\n",
    "gs_model_cv = gs_cv.fit(X_features_cv, dataset['label'])\n",
    "pd.DataFrame(gs_model_cv.cv_results_).sort_values('mean_test_score', ascending = False)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
